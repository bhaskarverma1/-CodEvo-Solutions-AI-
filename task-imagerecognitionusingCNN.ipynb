{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA9MymwtTs7YwCJchSMucM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaskarverma1/-CodEvo-Solutions-AI-/blob/main/task-imagerecognitionusingCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLY-dMjSnNEZ",
        "outputId": "434fbbbc-0728-4371-c562-9f4301c5a26e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 200ms/step - accuracy: 0.3514 - loss: 1.7509 - val_accuracy: 0.5948 - val_loss: 1.1192\n",
            "Epoch 2/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 204ms/step - accuracy: 0.5967 - loss: 1.1404 - val_accuracy: 0.6932 - val_loss: 0.8827\n",
            "Epoch 3/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 198ms/step - accuracy: 0.6648 - loss: 0.9494 - val_accuracy: 0.7027 - val_loss: 0.8515\n",
            "Epoch 4/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 200ms/step - accuracy: 0.7027 - loss: 0.8475 - val_accuracy: 0.7315 - val_loss: 0.7858\n",
            "Epoch 5/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 199ms/step - accuracy: 0.7272 - loss: 0.7807 - val_accuracy: 0.7416 - val_loss: 0.7504\n",
            "Epoch 6/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 200ms/step - accuracy: 0.7510 - loss: 0.7166 - val_accuracy: 0.7622 - val_loss: 0.6964\n",
            "Epoch 7/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 200ms/step - accuracy: 0.7643 - loss: 0.6777 - val_accuracy: 0.7547 - val_loss: 0.7092\n",
            "Epoch 8/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 202ms/step - accuracy: 0.7830 - loss: 0.6243 - val_accuracy: 0.7623 - val_loss: 0.6962\n",
            "Epoch 9/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 203ms/step - accuracy: 0.7860 - loss: 0.6106 - val_accuracy: 0.7704 - val_loss: 0.6687\n",
            "Epoch 10/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 201ms/step - accuracy: 0.7950 - loss: 0.5774 - val_accuracy: 0.7587 - val_loss: 0.7134\n",
            "Epoch 11/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 204ms/step - accuracy: 0.8059 - loss: 0.5506 - val_accuracy: 0.7849 - val_loss: 0.6533\n",
            "Epoch 12/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 203ms/step - accuracy: 0.8131 - loss: 0.5333 - val_accuracy: 0.7800 - val_loss: 0.6514\n",
            "Epoch 13/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 202ms/step - accuracy: 0.8172 - loss: 0.5127 - val_accuracy: 0.7788 - val_loss: 0.6858\n",
            "Epoch 14/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 207ms/step - accuracy: 0.8258 - loss: 0.5009 - val_accuracy: 0.7641 - val_loss: 0.7012\n",
            "Epoch 15/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 203ms/step - accuracy: 0.8300 - loss: 0.4793 - val_accuracy: 0.7740 - val_loss: 0.6875\n",
            "Epoch 16/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 199ms/step - accuracy: 0.8364 - loss: 0.4617 - val_accuracy: 0.7749 - val_loss: 0.6839\n",
            "Epoch 17/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 206ms/step - accuracy: 0.8406 - loss: 0.4471 - val_accuracy: 0.7817 - val_loss: 0.6808\n",
            "Epoch 18/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 202ms/step - accuracy: 0.8426 - loss: 0.4490 - val_accuracy: 0.7728 - val_loss: 0.7243\n",
            "Epoch 19/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 201ms/step - accuracy: 0.8436 - loss: 0.4466 - val_accuracy: 0.7762 - val_loss: 0.6884\n",
            "Epoch 20/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 200ms/step - accuracy: 0.8549 - loss: 0.4202 - val_accuracy: 0.7898 - val_loss: 0.6867\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 63ms/step - accuracy: 0.7913 - loss: 0.6845\n",
            "Test accuracy: 0.7897999882698059\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[848   7  26  10   7   6   8   9  46  33]\n",
            " [ 11 854   2   5   3   2   6   1  24  92]\n",
            " [ 73   1 626  49 108  42  63  15  14   9]\n",
            " [ 21   3  45 606  63 138  71  16  13  24]\n",
            " [ 17   3  25  47 827  19  29  23   6   4]\n",
            " [  7   2  24 160  50 681  30  25  10  11]\n",
            " [  8   2  18  31  34   9 885   1   9   3]\n",
            " [ 15   1  27  37  64  42   9 780   8  17]\n",
            " [ 40  12   7   7   6   1   8   1 900  18]\n",
            " [ 19  40   2   9   4   2   2   6  25 891]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82      1000\n",
            "           1       0.92      0.85      0.89      1000\n",
            "           2       0.78      0.63      0.69      1000\n",
            "           3       0.63      0.61      0.62      1000\n",
            "           4       0.71      0.83      0.76      1000\n",
            "           5       0.72      0.68      0.70      1000\n",
            "           6       0.80      0.89      0.84      1000\n",
            "           7       0.89      0.78      0.83      1000\n",
            "           8       0.85      0.90      0.88      1000\n",
            "           9       0.81      0.89      0.85      1000\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten the output\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_test, y_test))\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Confusion matrix\n",
        "predicted_classes = model.predict(x_test)\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "confusion_mtx = confusion_matrix(true_classes, predicted_classes)\n",
        "print('Confusion Matrix:\\n', confusion_mtx)\n",
        "print('Classification Report:\\n', classification_report(true_classes, predicted_classes))\n",
        "# Save the model\n",
        "model.save('cifar10_cnn_model.h5')"
      ]
    }
  ]
}